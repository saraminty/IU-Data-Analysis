{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a931d79",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-14T08:14:38.314013Z",
     "iopub.status.busy": "2025-02-14T08:14:38.313595Z",
     "iopub.status.idle": "2025-02-14T08:14:39.378121Z",
     "shell.execute_reply": "2025-02-14T08:14:39.376964Z"
    },
    "papermill": {
     "duration": 1.069349,
     "end_time": "2025-02-14T08:14:39.379748",
     "exception": false,
     "start_time": "2025-02-14T08:14:38.310399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/university-students-complaints-and-reports/Datasetprojpowerbi.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5ee481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T08:14:39.384828Z",
     "iopub.status.busy": "2025-02-14T08:14:39.384343Z",
     "iopub.status.idle": "2025-02-14T08:14:42.544622Z",
     "shell.execute_reply": "2025-02-14T08:14:42.543138Z"
    },
    "papermill": {
     "duration": 3.164477,
     "end_time": "2025-02-14T08:14:42.546157",
     "exception": false,
     "start_time": "2025-02-14T08:14:39.381680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "   15minut  30minut  abil       abl  abroad    academ  accent  accept  \\\n",
      "0      0.0      0.0   0.0  0.263485     0.0  0.194256     0.0     0.0   \n",
      "1      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "2      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "3      0.0      0.0   0.0  0.000000     0.0  0.169476     0.0     0.0   \n",
      "4      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "5      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "6      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "7      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "8      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "9      0.0      0.0   0.0  0.000000     0.0  0.157911     0.0     0.0   \n",
      "\n",
      "     access  accommod  ...  worth    would     write  writer  written   wrong  \\\n",
      "0  0.372093       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "1  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "2  0.175917       0.0  ...    0.0  0.00000  0.341139     0.0      0.0  0.0000   \n",
      "3  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "4  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "5  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "6  0.000000       0.0  ...    0.0  0.19239  0.000000     0.0      0.0  0.3454   \n",
      "7  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "8  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "9  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "\n",
      "   year  yet  your  zone  \n",
      "0   0.0  0.0   0.0   0.0  \n",
      "1   0.0  0.0   0.0   0.0  \n",
      "2   0.0  0.0   0.0   0.0  \n",
      "3   0.0  0.0   0.0   0.0  \n",
      "4   0.0  0.0   0.0   0.0  \n",
      "5   0.0  0.0   0.0   0.0  \n",
      "6   0.0  0.0   0.0   0.0  \n",
      "7   0.0  0.0   0.0   0.0  \n",
      "8   0.0  0.0   0.0   0.0  \n",
      "9   0.0  0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 1311 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/university-students-complaints-and-reports/Datasetprojpowerbi.csv\")\n",
    "\n",
    "df[\"Reports_lower\"] = df[\"Reports\"].str.lower()\n",
    "\n",
    "translator = str.maketrans(\" \",\" \",string.punctuation)\n",
    "df[\"Reports_nopunct\"] = df[\"Reports_lower\"].str.translate(translator)\n",
    "\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = {\"im\",\"really\",\"student\",\"like\",\"feel\",\"ive\"}\n",
    "combined_stopwords = english_stopwords.union(custom_stopwords)\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    improved_text = [word for word in words if word not in combined_stopwords and word not in translator and not word.isdigit()]\n",
    "    return \" \".join(improved_text)\n",
    "\n",
    "df[\"cleaned_Reports\"] = df[\"Reports_nopunct\"].apply(remove_stopwords)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "df[\"stemmed_Reports\"] = df[\"cleaned_Reports\"].apply(stem_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"stemmed_Reports\"])\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "print(tfidf_df.head(10).tail(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3260867,
     "sourceId": 6264732,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.448391,
   "end_time": "2025-02-14T08:14:43.369508",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-14T08:14:35.921117",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
