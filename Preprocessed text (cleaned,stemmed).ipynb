{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb40920",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-14T07:50:10.228329Z",
     "iopub.status.busy": "2025-02-14T07:50:10.227887Z",
     "iopub.status.idle": "2025-02-14T07:50:11.334864Z",
     "shell.execute_reply": "2025-02-14T07:50:11.333709Z"
    },
    "papermill": {
     "duration": 1.112699,
     "end_time": "2025-02-14T07:50:11.336928",
     "exception": false,
     "start_time": "2025-02-14T07:50:10.224229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/university-students-complaints-and-reports/Datasetprojpowerbi.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6abb8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T07:50:11.343129Z",
     "iopub.status.busy": "2025-02-14T07:50:11.342651Z",
     "iopub.status.idle": "2025-02-14T07:50:14.789020Z",
     "shell.execute_reply": "2025-02-14T07:50:14.787503Z"
    },
    "papermill": {
     "duration": 3.451054,
     "end_time": "2025-02-14T07:50:14.790974",
     "exception": false,
     "start_time": "2025-02-14T07:50:11.339920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "                                             Reports  \\\n",
      "0  The limited access to research databases and m...   \n",
      "1  I'm having trouble finding the course material...   \n",
      "2  It's frustrating to have limited access to res...   \n",
      "3  I'm really struggling in one of my classes but...   \n",
      "4   I am really struggling with understanding the...   \n",
      "5   The grading system in this course is unfair a...   \n",
      "6   I wish my professor would give us more feedba...   \n",
      "7   The quality of teaching in this course is ver...   \n",
      "8   The course fees and textbook costs are way to...   \n",
      "9  I am very concerned about academic dishonesty ...   \n",
      "\n",
      "                                     cleaned_Reports  \\\n",
      "0  limited access research databases materials ca...   \n",
      "1  trouble finding course materials need classes ...   \n",
      "2  frustrating limited access research databases ...   \n",
      "3  struggling one classes cant get appointment ac...   \n",
      "4  struggling understanding instructions assignme...   \n",
      "5  grading system course unfair inconsistent seem...   \n",
      "6  wish professor would give us feedback assignme...   \n",
      "7  quality teaching course poor professor doesnt ...   \n",
      "8  course fees textbook costs way high barely aff...   \n",
      "9  concerned academic dishonesty plagiarism cours...   \n",
      "\n",
      "                                     stemmed_Reports  \n",
      "0  limit access research databas materi caus lot ...  \n",
      "1  troubl find cours materi need class librari do...  \n",
      "2  frustrat limit access research databas materi ...  \n",
      "3  struggl one class cant get appoint academ advi...  \n",
      "4  struggl understand instruct assign clear dont ...  \n",
      "5  grade system cours unfair inconsist seem profe...  \n",
      "6  wish professor would give us feedback assign d...  \n",
      "7  qualiti teach cours poor professor doesnt seem...  \n",
      "8  cours fee textbook cost way high bare afford p...  \n",
      "9  concern academ dishonesti plagiar cours profes...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/university-students-complaints-and-reports/Datasetprojpowerbi.csv\")\n",
    "\n",
    "df[\"Reports_lower\"] = df[\"Reports\"].str.lower()\n",
    "\n",
    "translator = str.maketrans(\" \",\" \",string.punctuation)\n",
    "df[\"Reports_nopunct\"] = df[\"Reports_lower\"].str.translate(translator)\n",
    "\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = {\"im\",\"really\",\"student\",\"like\",\"feel\",\"ive\"}\n",
    "combined_stopwords = english_stopwords.union(custom_stopwords)\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    improved_text = [word for word in words if word not in combined_stopwords and word not in translator and not word.isdigit()]\n",
    "    return \" \".join(improved_text)\n",
    "\n",
    "df[\"cleaned_Reports\"] = df[\"Reports_nopunct\"].apply(remove_stopwords)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "df[\"stemmed_Reports\"] = df[\"cleaned_Reports\"].apply(stem_text)\n",
    "\n",
    "print(df[[\"Reports\", \"cleaned_Reports\", \"stemmed_Reports\"]].head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3260867,
     "sourceId": 6264732,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.101598,
   "end_time": "2025-02-14T07:50:15.615268",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-14T07:50:06.513670",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
