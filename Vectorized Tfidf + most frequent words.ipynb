{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cea37d4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-14T08:23:43.000137Z",
     "iopub.status.busy": "2025-02-14T08:23:42.999651Z",
     "iopub.status.idle": "2025-02-14T08:23:44.044222Z",
     "shell.execute_reply": "2025-02-14T08:23:44.042763Z"
    },
    "papermill": {
     "duration": 1.050418,
     "end_time": "2025-02-14T08:23:44.046350",
     "exception": false,
     "start_time": "2025-02-14T08:23:42.995932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/university-students-complaints-and-reports/Datasetprojpowerbi.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25284217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T08:23:44.052776Z",
     "iopub.status.busy": "2025-02-14T08:23:44.052226Z",
     "iopub.status.idle": "2025-02-14T08:23:47.563988Z",
     "shell.execute_reply": "2025-02-14T08:23:47.562646Z"
    },
    "papermill": {
     "duration": 3.516555,
     "end_time": "2025-02-14T08:23:47.565636",
     "exception": false,
     "start_time": "2025-02-14T08:23:44.049081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "   15minut  30minut  abil       abl  abroad    academ  accent  accept  \\\n",
      "0      0.0      0.0   0.0  0.263485     0.0  0.194256     0.0     0.0   \n",
      "1      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "2      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "3      0.0      0.0   0.0  0.000000     0.0  0.169476     0.0     0.0   \n",
      "4      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "5      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "6      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "7      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "8      0.0      0.0   0.0  0.000000     0.0  0.000000     0.0     0.0   \n",
      "9      0.0      0.0   0.0  0.000000     0.0  0.157911     0.0     0.0   \n",
      "\n",
      "     access  accommod  ...  worth    would     write  writer  written   wrong  \\\n",
      "0  0.372093       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "1  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "2  0.175917       0.0  ...    0.0  0.00000  0.341139     0.0      0.0  0.0000   \n",
      "3  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "4  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "5  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "6  0.000000       0.0  ...    0.0  0.19239  0.000000     0.0      0.0  0.3454   \n",
      "7  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "8  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "9  0.000000       0.0  ...    0.0  0.00000  0.000000     0.0      0.0  0.0000   \n",
      "\n",
      "   year  yet  your  zone  \n",
      "0   0.0  0.0   0.0   0.0  \n",
      "1   0.0  0.0   0.0   0.0  \n",
      "2   0.0  0.0   0.0   0.0  \n",
      "3   0.0  0.0   0.0   0.0  \n",
      "4   0.0  0.0   0.0   0.0  \n",
      "5   0.0  0.0   0.0   0.0  \n",
      "6   0.0  0.0   0.0   0.0  \n",
      "7   0.0  0.0   0.0   0.0  \n",
      "8   0.0  0.0   0.0   0.0  \n",
      "9   0.0  0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 1311 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/university-students-complaints-and-reports/Datasetprojpowerbi.csv\")\n",
    "\n",
    "df[\"Reports_lower\"] = df[\"Reports\"].str.lower()\n",
    "\n",
    "translator = str.maketrans(\" \",\" \",string.punctuation)\n",
    "df[\"Reports_nopunct\"] = df[\"Reports_lower\"].str.translate(translator)\n",
    "\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = {\"im\",\"really\",\"student\",\"like\",\"feel\",\"ive\"}\n",
    "combined_stopwords = english_stopwords.union(custom_stopwords)\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    improved_text = [word for word in words if word not in combined_stopwords and word not in translator and not word.isdigit()]\n",
    "    return \" \".join(improved_text)\n",
    "\n",
    "df[\"cleaned_Reports\"] = df[\"Reports_nopunct\"].apply(remove_stopwords)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "df[\"stemmed_Reports\"] = df[\"cleaned_Reports\"].apply(stem_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"stemmed_Reports\"])\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "print(tfidf_df.head(10).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9439363b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T08:23:47.571274Z",
     "iopub.status.busy": "2025-02-14T08:23:47.570930Z",
     "iopub.status.idle": "2025-02-14T08:23:47.603222Z",
     "shell.execute_reply": "2025-02-14T08:23:47.601596Z"
    },
    "papermill": {
     "duration": 0.037535,
     "end_time": "2025-02-14T08:23:47.605420",
     "exception": false,
     "start_time": "2025-02-14T08:23:47.567885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word  tfidf_score\n",
      "1103    student    36.850763\n",
      "1228    univers    28.569606\n",
      "8        access    28.494155\n",
      "5        academ    28.289367\n",
      "655       limit    27.049631\n",
      "439        find    26.602705\n",
      "786      option    26.039072\n",
      "83        avail    25.734455\n",
      "688        make    25.623847\n",
      "744        need    25.107747\n",
      "784    opportun    23.979267\n",
      "179       class    23.335904\n",
      "1166       time    22.860928\n",
      "241       cours    22.815588\n",
      "615         job    22.703614\n",
      "293   difficult    22.190598\n",
      "514        hard    22.053396\n",
      "781       onlin    21.959751\n",
      "145       campu    21.881768\n",
      "1285       wish    20.266363\n"
     ]
    }
   ],
   "source": [
    "sum_tfidf = np.array(tfidf_df.sum(axis=0)).flatten()\n",
    "words_tfidf_df = pd.DataFrame(list(zip(tfidf_df,sum_tfidf)), columns = [\"word\", \"tfidf_score\"])\n",
    "most_frequent_words = words_tfidf_df.sort_values(by=\"tfidf_score\", ascending=False)\n",
    "\n",
    "print(most_frequent_words.head(20))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3260867,
     "sourceId": 6264732,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.400082,
   "end_time": "2025-02-14T08:23:48.430439",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-14T08:23:40.030357",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
